{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "import xgboost\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('~/data/sberbank/transactions.csv')\n",
    "sex = pd.read_csv('~/data/sberbank/customers_gender_train.csv')\n",
    "\n",
    "sex = sex.set_index('customer_id')\n",
    "transactions = transactions.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_time(x):\n",
    "    x = x.split(' ')[1]\n",
    "    x = x.split(':')\n",
    "    return int(x[0])*60 + int(x[1])\n",
    "def regex(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    x = re.findall('[a-zA-Z]+', x)\n",
    "    if len(x) == 0:\n",
    "        return ''\n",
    "    return x[0]\n",
    "def return_pairs(l):\n",
    "    l = list(l)\n",
    "    pairs = []\n",
    "    for i in range(len(l) - 1):\n",
    "        pairs.append((l[i], l[i + 1]))\n",
    "    return pairs\n",
    "def return_pairs2(l):\n",
    "    l = list(l)\n",
    "    pairs = []\n",
    "    for i in range(len(l) - 2):\n",
    "        pairs.append((l[i], l[i + 1], l[i + 2]))\n",
    "    return pairs\n",
    "def create_range(series):\n",
    "    if len(series) < 2:\n",
    "        return 0\n",
    "    s = 0\n",
    "    n = 0\n",
    "    for i in range(len(series) - 1):\n",
    "        s += series[i + 1] - series[i]\n",
    "        n += 1\n",
    "    return s / n\n",
    "def prepeocessing(t, sex):\n",
    "    \n",
    "    users = t.index.unique()\n",
    "    users2 = sex.index.values\n",
    "    users_test = list(set.difference(set(users), users2))\n",
    "    \n",
    "    t['day'] = t.tr_datetime.apply(lambda x:int(x.split(' ')[0]))\n",
    "    t['time'] = t.tr_datetime.apply(get_time)\n",
    "    \n",
    "    \n",
    "    data = pd.DataFrame(index=t.index.unique())\n",
    "    \n",
    "    data['day_range'] = t.day.groupby(by=t.index).max() - t.day.groupby(by=t.index).min()\n",
    "    data['day_strange'] = t.day.groupby(by=t.index).median() \\\n",
    "        - (t.day.groupby(by=t.index).max() + t.day.groupby(by=t.index).min()) / 2\n",
    "    data['amount_min'] = t.amount.groupby(by=t.index).min()\n",
    "    data['amount_max'] = t.amount.groupby(by=t.index).max()\n",
    "    data['amount_mean'] = t.amount.groupby(by=t.index).mean()\n",
    "    data['amount_mean2'] = t.amount[t.amount < 0].groupby(by=t.index[t.amount < 0]).mean()\n",
    "    data['amount_median'] = t.amount.groupby(by=t.index).median()\n",
    "    data['amount_median2'] = t.amount[t.amount < 0].groupby(by=t.index[t.amount < 0]).median()\n",
    "    data['amount_sum'] = t.amount.groupby(by=t.index).sum()\n",
    "    data['amount_sum2'] = t.amount[t.amount < 0].groupby(by=t.index[t.amount < 0]).sum()\n",
    "    data['time_mean'] = t.time.groupby(by=t.index).mean()\n",
    "    data['time_median'] = t.time.groupby(by=t.index).median()\n",
    "    data['time_std'] = t.time.groupby(by=t.index).std()\n",
    "    tmp = t[t.time != 0]\n",
    "    data['time_std2'] = tmp.time.groupby(by=tmp.index).std()\n",
    "    \n",
    "    \n",
    "    tmp = t.reset_index().groupby(['customer_id', 'day']).apply(len).reset_index()\n",
    "    data['median_transaction_at_day'] = tmp[0].groupby(tmp.customer_id).median()\n",
    "    \n",
    "    tmp = pd.get_dummies(t.mcc_code, prefix='mcc_code').groupby(by=t.index).sum()\n",
    "    data = data.join(tmp)\n",
    "    \n",
    "    tmp = pd.get_dummies(t.mcc_code, prefix='mcc_code__').groupby(by=t.index).mean()\n",
    "    data = data.join(tmp)\n",
    "    \n",
    "    tmp = pd.get_dummies(t.tr_type, prefix='tr_type').groupby(by=t.index).sum()\n",
    "    data = data.join(tmp)\n",
    "    \n",
    "    tmp = t.reset_index().groupby(['customer_id', 'mcc_code'])['amount'].mean().reset_index()\n",
    "    tmp = tmp.pivot(index='customer_id', columns='mcc_code', values='amount').fillna(0)\n",
    "    tmp.columns = [str(col) + '_amount' for col in tmp.columns]\n",
    "    data = data.join(tmp)\n",
    "    \n",
    "    index = ((t.day > 217) & (t.day <= 219) | (t.day > 149) \\\n",
    "        & (t.day <= 152)) & (t.mcc_code == 5944)\n",
    "    tmp = t[index]\n",
    "    data['jewelry_8March_NewYear'] = tmp.amount.groupby(by=tmp.index).apply(len)\n",
    "    \n",
    "    index = (t.day > 218) & (t.day <= 219) & (t.mcc_code == 5992)\n",
    "    tmp = t[index]\n",
    "    data['flowers_8March'] = tmp.amount.groupby(by=tmp.index).apply(len)\n",
    "    \n",
    "    index = (t.day > 204) & (t.day <= 206) & (t.mcc_code == 5947)\n",
    "    tmp2 = t[index]\n",
    "    data['menswear_23Febrary'] = tmp.amount.groupby(by=tmp.index).apply(len)\n",
    "    \n",
    "    index = (t.day > 204) & (t.day <= 206) & (t.mcc_code == 5611)\n",
    "    tmp2 = t[index]\n",
    "    data['gift_23Febrary'] = tmp.amount.groupby(by=tmp.index).apply(len)\n",
    "    \n",
    "    tmp = t[t.amount < 0]\n",
    "    codes = [5065,5072,5074,5094,5131,5511,5532,5533,5542,5571,5599,5611,\n",
    "             5621,5631,5681,5681,5714,5734,5812,5945,5947,5949,5977,5993,7230]\n",
    "    index = np.array([i in codes for i in tmp.mcc_code.values])\n",
    "    tmp = tmp[index]\n",
    "    d = {}\n",
    "    index = tmp.index.values\n",
    "    mcc = ['mcc_amount_' + str(i) for i in tmp.mcc_code.values]\n",
    "    amount = tmp.amount.values\n",
    "    for i in range(len(index)):\n",
    "        d[index[i]] = {}\n",
    "    for i in range(len(index)):\n",
    "        if mcc[i] not in d[index[i]]:\n",
    "            d[index[i]][mcc[i]] = amount[i]\n",
    "        else:\n",
    "            d[index[i]][mcc[i]] += amount[i]\n",
    "    tmp = pd.DataFrame(d)\n",
    "    tmp = tmp.transpose()\n",
    "    tmp = tmp.fillna(0)\n",
    "    tmp = -tmp\n",
    "    norm = Normalizer(norm='l1')\n",
    "    pca = PCA(n_components=3)\n",
    "    result2 = pca.fit_transform(norm.fit_transform(tmp))\n",
    "    data['pca1'] = np.nan\n",
    "    data.loc[tmp.index, 'pca1'] = result2[:,0]\n",
    "    \n",
    "    tmp = t.mcc_code.groupby(by=t.index).apply(return_pairs)\n",
    "    l = []\n",
    "    for i in tmp.values:\n",
    "        l += i\n",
    "    result = Counter(l)\n",
    "     \n",
    "    for i in result.most_common()[:180]:\n",
    "        index = [i[0] in pairs for pairs in tmp.values]\n",
    "        data['Counter' + str(i[0])] = False\n",
    "        data.loc[tmp[index].index, 'Counter' + str(i[0])] = True\n",
    "\n",
    "    tmp = t[((t.day % 7 ==  1) | (t.day % 7  == 2)) & (t.amount < 0)]\n",
    "    \n",
    "    tmp = pd.get_dummies(tmp.mcc_code, prefix='mcc_code_weekday1').groupby(by=tmp.index).mean()\n",
    "    data = data.join(tmp)\n",
    "    \n",
    "    tmp = t[t.amount < 0]\n",
    "    tmp['weekday'] = abs(tmp.day % 7 - 1.5) < 1\n",
    "    tmp2 = tmp[np.invert(tmp.weekday)].reset_index().groupby(['customer_id', 'mcc_code']).apply(len).reset_index()\n",
    "    tmp3 = tmp[tmp.weekday].reset_index().groupby(['customer_id', 'mcc_code']).apply(len).reset_index()\n",
    "    tmp2 = tmp2.pivot(index = 'customer_id', columns = 'mcc_code', values=0).fillna(0)\n",
    "    tmp3 = tmp3.pivot(index = 'customer_id', columns = 'mcc_code', values=0).fillna(0)\n",
    "    tmp2 = tmp2 + 1\n",
    "    tmp3 = tmp3 + 1\n",
    "    tmp = tmp2 / tmp3\n",
    "    tmp.columns = [str(col) + 'weekday' for col in tmp.columns]\n",
    "    data = data.join(tmp)\n",
    "    \n",
    "    tmp = t[t.amount < 0]\n",
    "    tmp['weekday'] = abs(tmp.day % 7 - 1.5) < 1\n",
    "    weekday = pd.Series(index=tmp.index.unique())\n",
    "    weekday.loc[weekday.index] = 0\n",
    "    tmp2 = tmp[np.invert(tmp.weekday)].groupby(tmp[np.invert(tmp.weekday)].index).apply(len)\n",
    "    weekday.loc[tmp2.index] = tmp2\n",
    "    weekday += 1\n",
    "    weekend = pd.Series(index=tmp.index.unique())\n",
    "    weekend.loc[weekend.index] = 0\n",
    "    tmp3 = tmp[tmp.weekday].groupby(tmp[tmp.weekday].index).apply(len)\n",
    "    weekend.loc[tmp3.index] = tmp3\n",
    "    weekend += 1\n",
    "    data['share_week'] = weekday / weekend\n",
    "    \n",
    "    tmp = t.reset_index().groupby(['customer_id', 'day'])['time'].apply(list)\n",
    "    tmp2 = tmp.apply(np.std)\n",
    "    tmp2 = tmp2[tmp2 != 0]\n",
    "    tmp2 = tmp2.reset_index().groupby('customer_id')['time'].mean()\n",
    "    data['std_time_over_day'] = tmp2\n",
    "    tmp = t[t.time!= 0].reset_index().groupby(['customer_id', 'day'])['time'].apply(list)\n",
    "    tmp2 = tmp.apply(create_range)\n",
    "    tmp2 = tmp2[tmp2 != 0]\n",
    "    tmp2 = tmp2.reset_index().groupby('customer_id')['time'].mean()\n",
    "    data['range_time_over_day'] = tmp2\n",
    "\n",
    "    X = data.loc[users2]\n",
    "    y = sex.gender\n",
    "    \n",
    "    XTEST = data.loc[users_test]\n",
    "    \n",
    "    return X, y, XTEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 27s, sys: 27.9 s, total: 6min 55s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, XTEST = prepeocessing(transactions, sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = xgboost.XGBClassifier(n_estimators=1288, max_depth=1, seed=2, subsample=0.55, nthread=8)\n",
    "model2 = xgboost.XGBClassifier(n_estimators=704,  max_depth=2, seed=2, subsample=0.7,  nthread=8)\n",
    "model3 = xgboost.XGBClassifier(n_estimators=342,  max_depth=3, seed=2, subsample=0.7,  nthread=8)\n",
    "model4 = xgboost.XGBClassifier(n_estimators=1288, max_depth=1, seed=1, subsample=0.55, nthread=8)\n",
    "model5 = xgboost.XGBClassifier(n_estimators=704,  max_depth=2, seed=1, subsample=0.7,  nthread=8)\n",
    "model6 = xgboost.XGBClassifier(n_estimators=342,  max_depth=3, seed=1, subsample=0.7,  nthread=8)\n",
    "model7 = xgboost.XGBClassifier(n_estimators=216,  max_depth=4, seed=1, subsample=0.8,  nthread=8)\n",
    "model8 = xgboost.XGBClassifier(n_estimators=235,  max_depth=5, seed=1, subsample=0.8,  nthread=8)\n",
    "model9 = xgboost.XGBClassifier(n_estimators=286,  max_depth=6, seed=1, subsample=0.8,  nthread=8)\n",
    "model10 = xgboost.XGBClassifier(n_estimators=450,  max_depth=7, seed=1, subsample=0.9,  nthread=8)\n",
    "model11 = xgboost.XGBClassifier(n_estimators=450,  max_depth=8, seed=1, subsample=0.9,  nthread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = [pd.Series(index=X.index) for i in range(9)]\n",
    "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9]\n",
    "for train, test in KFold(len(X), n_folds=10, shuffle=True, random_state=241):\n",
    "    for i in range(9):\n",
    "        models[i].fit(X.iloc[train], y.iloc[train])\n",
    "        proba[i].iloc[test] = models[i].predict_proba(X.iloc[test])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba.append(pd.Series(index=X.index))\n",
    "proba.append(pd.Series(index=X.index))\n",
    "for train, test in KFold(len(X), n_folds=10, shuffle=True, random_state=241):\n",
    "    model10.fit(X.iloc[train], y.iloc[train])\n",
    "    model11.fit(X.iloc[train], y.iloc[train])\n",
    "    proba[9].iloc[test] = model10.predict_proba(X.iloc[test])[:,1]\n",
    "    proba[10].iloc[test] = model11.predict_proba(X.iloc[test])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_blending_coefficient(y, proba, max_iter=100, verbose=False):\n",
    "    B = np.transpose(proba)\n",
    "    n = len(proba)\n",
    "    a = np.array([6]*n)\n",
    "    roc_old = roc_auc_score(y, (B * a).mean(axis=1))\n",
    "    for i in range(max_iter):\n",
    "        a[i % n] += 1\n",
    "        roc_new = roc_auc_score(y, (B * a).mean(axis=1))\n",
    "        if roc_new < roc_old:\n",
    "            a[i % n] += -2\n",
    "            roc_new = roc_auc_score(y, (B * a).mean(axis=1))\n",
    "            if roc_new <= roc_old:\n",
    "                a[i % n] += 1\n",
    "                roc_new = roc_old\n",
    "        roc_old = roc_new\n",
    "        if verbose:\n",
    "            print(a, roc_old)\n",
    "    a[a < 0] = 0\n",
    "    print(roc_old, a)\n",
    "    return a / a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891763821104 [ 3 12  3  8 10 10  1  3  0  4  9]\n"
     ]
    }
   ],
   "source": [
    "a = create_blending_coefficient(y, proba, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probaTEST = []\n",
    "for i in range(9):\n",
    "    models[i].fit(X, y)\n",
    "    probaTEST.append(models[i].predict_proba(XTEST)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model10.fit(X, y)\n",
    "model11.fit(X, y)\n",
    "probaTEST.append(model10.predict_proba(XTEST)[:,1])\n",
    "probaTEST.append(model11.predict_proba(XTEST)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(a.dot(probaTEST), XTEST.index, columns=['gender'])\n",
    "submit = submit.sort_index().reset_index()\n",
    "submit.columns = ['customer_id', 'gender']\n",
    "submit.to_csv('A.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
